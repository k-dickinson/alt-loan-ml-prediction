# Alternative Credit Scoring Machine Learning Pipeline

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)]()

This project implements a **production-ready machine learning pipeline** for alternative credit scoring that predicts loan default probability using alternative data sources, **completely excluding traditional credit score and credit history information**.

## Project Overview

Traditional credit scoring relies heavily on credit history, credit scores, and previous loan performance. This alternative approach uses **alternative data sources** to evaluate creditworthiness, making it suitable for:

- **Individuals with limited or no credit history**
- **New immigrants or young adults**
- **People rebuilding their credit**
- **Markets where traditional credit data is unavailable**
- **Financial inclusion initiatives**

## Key Features

### ‚úÖ **Alternative Data Sources Used**
- **Demographic Information**: Age, marital status, number of dependents
- **Financial Profile**: Annual income, monthly income, savings/checking balances
- **Employment Data**: Employment status, job tenure, experience level
- **Education**: Education level
- **Housing**: Home ownership status
- **Loan Characteristics**: Loan amount, duration, purpose, monthly payments
- **Financial Ratios**: Debt-to-income ratio, total debt-to-income ratio
- **Payment Behavior**: Utility bills payment history
- **Asset Information**: Total assets, liabilities, net worth
- **Interest Rates**: Base and actual interest rates

### ‚ùå **Excluded Traditional Credit Features**
- Credit score
- Number of open credit lines
- Number of credit inquiries
- Length of credit history
- Payment history
- Previous loan defaults
- Bankruptcy history
- Credit card utilization rate

## Model Architecture

### **Algorithm Choice: LightGBM**
We chose **LightGBM** over XGBoost for the following reasons:

1. **Categorical Feature Handling**: Native support for categorical features, crucial for this dataset
2. **Speed**: Generally faster to train, especially with large datasets
3. **Memory Efficiency**: More memory-efficient than XGBoost
4. **Gradient-based One-Side Sampling**: Reduces overfitting while maintaining accuracy
5. **Leaf-wise Growth**: Often produces better accuracy than level-wise growth

### **Model Features**
- **Cross-validation** with early stopping to prevent overfitting
- **Feature encoding**: Frequency encoding for high-cardinality features, label encoding for low-cardinality
- **Missing value handling**: Median imputation for numerical, mode for categorical
- **Feature scaling**: StandardScaler for numerical features
- **Stratified sampling**: Ensures balanced representation in train/test splits

## Performance Metrics

The model evaluates performance using:
- **AUC (Area Under ROC Curve)**: Measures the model's ability to distinguish between classes
- **F1 Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: Detailed breakdown of predictions vs actual outcomes
- **Precision-Recall Curve**: Important for imbalanced datasets

## Model Interpretability

### **Feature Importance Analysis**
- **Traditional importance scores**: Bar chart of most important features
- **Business rules**: Actionable recommendations for loan approval
- **Risk assessment**: Clear probability-based decision making

### **Business Rules**
The model generates loan approval recommendations based on default probability:
- **Low Risk (< 30%)**: ‚úÖ APPROVE
- **Medium Risk (30-60%)**: ‚ö†Ô∏è REVIEW
- **High Risk (> 60%)**: ‚ùå DECLINE

## üìà Model Performance

Our alternative credit scoring model achieves excellent performance:

- **AUC Score**: 0.9588 (Excellent discrimination ability)
- **F1 Score**: 0.9349 (Strong precision and recall balance)
- **Accuracy**: 89.88% (High overall accuracy)
- **No Overfitting**: Training and testing performance are closely aligned

## Usage Example

### **Example Prediction**

```python
# Sample applicant data
applicant = {
    'Age': 35,
    'AnnualIncome': 50000,
    'EmploymentStatus': 'Employed',
    'EducationLevel': 'Bachelor',
    'Experience': 10,
    'LoanAmount': 20000,
    'LoanDuration': 36,
    'MaritalStatus': 'Married',
    'NumberOfDependents': 2,
    'HomeOwnershipStatus': 'Mortgage',
    'MonthlyDebtPayments': 500,
    'LoanPurpose': 'Debt Consolidation',
    'SavingsAccountBalance': 5000,
    'CheckingAccountBalance': 2000,
    'TotalAssets': 100000,
    'TotalLiabilities': 50000,
    'MonthlyIncome': 4000,
    'UtilityBillsPaymentHistory': 5,
    'JobTenure': 5,
    'NetWorth': 50000,
    'BaseInterestRate': 5.0,
    'InterestRate': 7.0,
    'MonthlyLoanPayment': 600,
    'TotalDebtToIncomeRatio': 0.3
}

# Get prediction
prediction = scorer.predict_loan_approval(applicant)
print(f"Recommendation: {prediction['recommendation']}")
print(f"Risk Level: {prediction['risk_level']}")
```

### **Expected Output**

The pipeline generates:
- **Performance metrics**: AUC, F1 score, accuracy
- **Visualizations**: 5 comprehensive analysis plots shown below
- **Sample analysis**: Complete applicant breakdown
- **Clean terminal output**: Only final summary

## üì∏ Visualizations Generated

The pipeline generates comprehensive visualizations for complete analysis:

### **1. Confusion Matrix with Accuracy**
![Confusion Matrix](https://github.com/k-dickinson/alt-loan-ml-prediction/blob/main/graphs/confusion_matrix.png)
*Shows model performance with accuracy percentage displayed*

### **2. Precision-Recall Curve**
![Precision-Recall](https://github.com/k-dickinson/alt-loan-ml-prediction/blob/main/graphs/precision_recall_curve.png)
*Precision-recall analysis for imbalanced dataset evaluation*

### **3. Comprehensive Overfitting Analysis (4-Panel)**
![Overfitting Analysis](https://github.com/k-dickinson/alt-loan-ml-prediction/blob/main/graphs/comprehensive_overfitting_analysis.png)
*Four-panel analysis showing:*
- Training vs Testing ROC curves
- Performance metrics comparison
- Performance differences
- Overfitting status summary

### **4. Feature Importance**
![Feature Importance](https://github.com/k-dickinson/alt-loan-ml-prediction/blob/main/graphs/feature_importance.png)
*Bar chart of the 15 most important features*

### **5. Sample Applicant Analysis (4-Panel)**
![Applicant Analysis](https://github.com/k-dickinson/alt-loan-ml-prediction/blob/main/graphs/applicant_analysis.png)
*Comprehensive applicant breakdown showing:*
- Applicant summary with key data
- Top contributing factors
- Risk assessment pie chart
- Recommendation analysis

## Key Features of the Implementation

### **1. Robust Preprocessing**
- **Missing Value Handling**: Intelligent imputation based on data type
- **Categorical Encoding**: Adaptive encoding strategy based on cardinality
- **Feature Scaling**: Standardization for numerical features
- **Data Validation**: Checks for data quality and consistency

### **2. Model Training**
- **Cross-validation**: 5-fold stratified cross-validation
- **Early Stopping**: Prevents overfitting with validation set monitoring
- **Hyperparameter Optimization**: Pre-tuned parameters for optimal performance
- **Stratified Sampling**: Maintains class balance in train/test splits

### **3. Comprehensive Evaluation**
- **Multiple Metrics**: AUC, F1, precision, recall, specificity
- **Visual Analysis**: ROC curves, confusion matrices, feature importance
- **Business Rules**: Actionable recommendations for loan approval
- **Overfitting Detection**: Training vs testing performance comparison

### **4. Production Ready**
- **Modular Design**: Clean, reusable code structure
- **Error Handling**: Robust error handling and validation
- **Documentation**: Comprehensive docstrings and comments
- **Scalability**: Designed to handle large datasets efficiently

## Business Impact

This alternative credit scoring system provides several advantages:

1. **Financial Inclusion**: Enables lending to underserved populations
2. **Risk Assessment**: Provides reliable risk evaluation without traditional credit data
3. **Regulatory Compliance**: Can be designed to avoid discriminatory practices
4. **Scalability**: Can be deployed across different markets and demographics
5. **Transparency**: Clear explanations for decisions

## üíª Full Code Repository

**Complete source code available [here](https://github.com/k-dickinson/alt-loan-ml-prediction/blob/main/main.py)**

## Future Enhancements

Potential improvements for the model:
- **Ensemble Methods**: Combine multiple models for better performance
- **Feature Engineering**: Create derived features from existing data
- **Real-time Scoring**: API deployment for real-time predictions
- **A/B Testing**: Framework for model comparison and validation
- **Regulatory Compliance**: Built-in fairness and bias detection
- **Web Interface**: User-friendly dashboard for loan officers
- **API Integration**: RESTful API for external systems

## Installation & Setup

### **Prerequisites**
- Python 3.8 or higher
- pip package manager

### **Quick Start**

1. **Clone the repository:**
```bash
git clone https://github.com/k-dickinson/alt-loan-ml-prediction.git
cd alt-loan-ml-model
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Run the pipeline:**
```bash
python main.py
```

This will:
1. ‚úÖ Load and preprocess the dataset
2. ‚úÖ Train the LightGBM model with cross-validation
3. ‚úÖ Evaluate performance metrics
4. ‚úÖ Generate comprehensive visualizations
5. ‚úÖ Create sample applicant analysis
6. ‚úÖ Output final summary

## üìÅ Project Structure

```
alt-loan-ml-model/
‚îú‚îÄ‚îÄ main.py                          # Main pipeline script
‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îú‚îÄ‚îÄ Loan new datset.csv             # Dataset (not included in repo)
‚îú‚îÄ‚îÄ confusion_matrix.png             # Generated visualization
‚îú‚îÄ‚îÄ precision_recall_curve.png       # Generated visualization
‚îú‚îÄ‚îÄ comprehensive_overfitting_analysis.png  # Generated visualization
‚îú‚îÄ‚îÄ feature_importance.png           # Generated visualization
‚îî‚îÄ‚îÄ applicant_analysis.png           # Generated visualization
```

## Requirements

```
pandas>=1.5.0
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
scikit-learn>=1.1.0
lightgbm>=3.3.0
xgboost>=1.6.0
```

## Contributing

We welcome contributions! Please feel free to submit issues, feature requests, or pull requests.

### **How to Contribute:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## Contact

**Instagram**: @Quant_Kyle

## Acknowledgments

- **Dataset**: [LINK](https://www.kaggle.com/datasets/willianoliveiragibin/financial-risk-v2?resource=download)
- **LightGBM**: Microsoft's gradient boosting framework
- **Scikit-learn**: Machine learning library

---

**‚≠ê Star this repository if you find it helpful!**
